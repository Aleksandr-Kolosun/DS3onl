{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.14808246]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class DenseNN(tf.Module):\n",
    "    def __init__(self, outputs):\n",
    "        super().__init__()\n",
    "        self.outputs = outputs\n",
    "        self.fl_init = False\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not self.fl_init:\n",
    "            self.w = tf.random.truncated_normal((x.shape[-1], self.outputs), stddev=0.1, name=\"w\")\n",
    "            self.b = tf.zeros([self.outputs], dtype=tf.float32, name=\"b\")\n",
    "\n",
    "            self.w = tf.Variable(self.w)\n",
    "            self.b = tf.Variable(self.b)\n",
    "\n",
    "            self.fl_init = True\n",
    "\n",
    "        y = x @ self.w + self.b # \n",
    "        return y\n",
    "\n",
    "\n",
    "model = DenseNN(1)\n",
    "\n",
    "print( model(tf.constant([[1.0, 2.0]])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
      "array([[-0.0234493 ],\n",
      "       [ 0.08576588]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "print(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04922606\n",
      "0.0010797665\n",
      "0.002377578\n",
      "0.0046391655\n",
      "0.0043057897\n",
      "0.0031892825\n",
      "0.0020550727\n",
      "0.0011779849\n",
      "0.0006086856\n",
      "0.00028587005\n",
      "0.000122044235\n",
      "4.7056572e-05\n",
      "1.618897e-05\n",
      "4.8952643e-06\n",
      "1.2922683e-06\n",
      "2.9653256e-07\n",
      "6.0071216e-08\n",
      "1.08057066e-08\n",
      "1.8417268e-09\n",
      "2.9467628e-10\n",
      "3.274181e-11\n",
      "3.637979e-12\n",
      "9.094947e-13\n",
      "9.094947e-13\n",
      "9.094947e-13\n",
      "9.094947e-13\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "(<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([2.84924e-08], dtype=float32)>, <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
      "array([[1.],\n",
      "       [1.]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "#print( model(tf.constant([[1.0, 2.0]])) )\n",
    "\n",
    "x_train = tf.random.uniform(minval=0, maxval=10, shape=(100, 2))\n",
    "y_train = [a + b for a, b in x_train] \n",
    "\n",
    "loss = lambda x, y: tf.reduce_mean(tf.square(x - y))\n",
    "opt = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "EPOCHS = 20\n",
    "for n in range(EPOCHS):\n",
    "    for x, y in zip(x_train, y_train):\n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        y = tf.constant(y, shape=(1, 1)) \n",
    "        with tf.GradientTape() as tape:\n",
    "            f_loss = loss(y, model(x))\n",
    "\n",
    "        grads = tape.gradient(f_loss, model.trainable_variables)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    print(f_loss.numpy())\n",
    "\n",
    "print(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[1 - 1] 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = f(x) -> loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507.08713\n",
      "214.69572\n",
      "144.48116\n",
      "106.609665\n",
      "82.63441\n",
      "62.94324\n",
      "50.177147\n",
      "40.32832\n",
      "31.447765\n",
      "26.596634\n",
      "97.61\n",
      "97.61000275611877\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DenseNN(tf.Module):\n",
    "    def __init__(self, outputs, activate=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.outputs = outputs\n",
    "        self.activate = activate\n",
    "        self.fl_init = False\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not self.fl_init:\n",
    "            self.w = tf.random.truncated_normal((x.shape[-1], self.outputs), stddev=0.1, name=\"w\")\n",
    "            self.b = tf.zeros([self.outputs], dtype=tf.float32, name=\"b\")\n",
    "\n",
    "            self.w = tf.Variable(self.w)\n",
    "            self.b = tf.Variable(self.b, trainable=False)\n",
    "\n",
    "            self.fl_init = True\n",
    "\n",
    "        y = x @ self.w + self.b\n",
    "\n",
    "        if self.activate == \"relu\":\n",
    "            return tf.nn.relu(y)\n",
    "        elif self.activate == \"softmax\":\n",
    "            return tf.nn.softmax(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class SequentialModule(tf.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = DenseNN(128)\n",
    "        self.layer_2 = DenseNN(10, activate=\"softmax\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.layer_2(self.layer_1(x))\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train = tf.reshape(tf.cast(x_train, tf.float32), [-1, 28*28])\n",
    "x_test = tf.reshape(tf.cast(x_test, tf.float32), [-1, 28*28])\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "\n",
    "\n",
    "model = SequentialModule()\n",
    "# layer_1 = DenseNN(128)\n",
    "# layer_2 = DenseNN(10, activate=\"softmax\")\n",
    "#print(model.submodules)\n",
    "\n",
    "cross_entropy = lambda y_true, y_pred: tf.reduce_mean(tf.losses.categorical_crossentropy(y_true, y_pred))\n",
    "opt = tf.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "TOTAL = x_train.shape[0]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_batch(x_batch, y_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        f_loss = cross_entropy(y_batch, model(x_batch))\n",
    "\n",
    "    grads = tape.gradient(f_loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    return f_loss\n",
    "\n",
    "\n",
    "for n in range(EPOCHS):\n",
    "    loss = 0\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        loss += train_batch(x_batch, y_batch)\n",
    "\n",
    "    print(loss.numpy())\n",
    "\n",
    "\n",
    "y = model(x_test)\n",
    "y2 = tf.argmax(y, axis=1).numpy()\n",
    "acc = len(y_test[y_test == y2])/y_test.shape[0] * 100\n",
    "print(acc)\n",
    "\n",
    "acc = tf.metrics.Accuracy()\n",
    "acc.update_state(y_test, y2)\n",
    "print( acc.result().numpy() * 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager conv: 0.005080399999314977\n",
      "Function conv: 0.007838600000468432\n",
      "Note how there's not much difference in performance for convolutions\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "conv_layer = tf.keras.layers.Conv2D(100, 3)\n",
    "\n",
    "@tf.function\n",
    "def conv_fn(image):\n",
    "  return conv_layer(image)\n",
    "\n",
    "image = tf.zeros([1, 200, 200, 100])\n",
    "# Warm up\n",
    "conv_layer(image); conv_fn(image)\n",
    "print(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number=10))\n",
    "print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))\n",
    "print(\"Note how there's not much difference in performance for convolutions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 40s 0us/step\n",
      "170508288/170498071 [==============================] - 40s 0us/step\n",
      "Epoch 1/15\n",
      "625/625 [==============================] - 22s 17ms/step - loss: 1.7680 - accuracy: 0.3206 - val_loss: 1.4518 - val_accuracy: 0.4574\n",
      "Epoch 2/15\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 1.3189 - accuracy: 0.5200 - val_loss: 1.1677 - val_accuracy: 0.5753\n",
      "Epoch 3/15\n",
      "625/625 [==============================] - 10s 15ms/step - loss: 1.0966 - accuracy: 0.6070 - val_loss: 1.0543 - val_accuracy: 0.6269\n",
      "Epoch 4/15\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.9537 - accuracy: 0.6599 - val_loss: 0.9067 - val_accuracy: 0.6731\n",
      "Epoch 5/15\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.8557 - accuracy: 0.6976 - val_loss: 0.8841 - val_accuracy: 0.6799\n",
      "Epoch 6/15\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 0.7772 - accuracy: 0.7247 - val_loss: 0.7543 - val_accuracy: 0.7337\n",
      "Epoch 7/15\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.7156 - accuracy: 0.7508 - val_loss: 0.7216 - val_accuracy: 0.7464\n",
      "Epoch 8/15\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.6541 - accuracy: 0.7728 - val_loss: 0.7445 - val_accuracy: 0.7410\n",
      "Epoch 9/15\n",
      "625/625 [==============================] - 9s 15ms/step - loss: 0.5979 - accuracy: 0.7924 - val_loss: 0.6972 - val_accuracy: 0.7547\n",
      "Epoch 10/15\n",
      "625/625 [==============================] - 10s 15ms/step - loss: 0.5580 - accuracy: 0.8061 - val_loss: 0.7312 - val_accuracy: 0.7451\n",
      "Epoch 11/15\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.5183 - accuracy: 0.8201 - val_loss: 0.7134 - val_accuracy: 0.7575\n",
      "Epoch 12/15\n",
      "625/625 [==============================] - 10s 17ms/step - loss: 0.4818 - accuracy: 0.8324 - val_loss: 0.6502 - val_accuracy: 0.7825\n",
      "Epoch 13/15\n",
      "625/625 [==============================] - 9s 15ms/step - loss: 0.4529 - accuracy: 0.8432 - val_loss: 0.7285 - val_accuracy: 0.7572\n",
      "Epoch 14/15\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.4122 - accuracy: 0.8569 - val_loss: 0.7133 - val_accuracy: 0.7796\n",
      "Epoch 15/15\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.3933 - accuracy: 0.8647 - val_loss: 0.7129 - val_accuracy: 0.7764\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.7528 - accuracy: 0.7669\n",
      "[0.7527703046798706, 0.7669000029563904]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import cifar10, mnist\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "inputs = keras.Input(shape=(32, 32, 3), name=\"img\")\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "block_1_output = layers.MaxPooling2D(3)(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_1_output)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_2_output = layers.add([x, block_1_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_2_output)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_3_output = layers.add([x, block_2_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\")(block_3_output)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs, name=\"toy_resnet\")\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=15, validation_split=0.2)\n",
    "\n",
    "print( model.evaluate(x_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(conv2D) (input)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"toy_resnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " img (InputLayer)               [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 30, 30, 32)   896         ['img[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 28, 28, 64)   18496       ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 9, 9, 64)     0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 9, 9, 64)     36928       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 9, 9, 64)     36928       ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 9, 9, 64)     0           ['conv2d_3[0][0]',               \n",
      "                                                                  'max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 9, 9, 64)     36928       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 9, 9, 64)     36928       ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 9, 9, 64)     0           ['conv2d_5[0][0]',               \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 7, 7, 64)     36928       ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 64)          0           ['conv2d_6[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          16640       ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           2570        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 223,242\n",
      "Trainable params: 223,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "x =tf.Variable(-2, dtype=tf.float32)   #y = x**2 -> -2 - > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    y=x**2\n",
    "df = tape.gradient(y,x)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dy/dx = 2x = 2*(-2) = -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w =tf.Variable(tf.random.normal((3,2)))\n",
    "b =tf.Variable(tf.zeros(2,dtype=tf.float32))\n",
    "x =tf.Variable([[-2.,1.,3.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 3) dtype=float32, numpy=array([[-2.,  1.,  3.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
      "array([[  7.8689256,  -2.1992188],\n",
      "       [ -3.9344628,   1.0996094],\n",
      "       [-11.803389 ,   3.2988281]], dtype=float32)>, None]\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    y=x@w + b\n",
    "    loss =tf.reduce_mean(y**2)\n",
    "df = tape.gradient(loss,[w,b])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =tf.Variable(0, dtype=tf.float32) #trinable=False\n",
    "b =tf.Variable(1.5) # Variable #+1 # Constant\n",
    "with tf.GradientTape() as tape:\n",
    "    f = (x+b)**2 + 2*b\n",
    "df = tape.gradient(f,[x,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(df[0])\n",
    "print(df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =tf.Variable([1.,2.]) #trinable=False\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.reduce_sum([2.,3.]*x**2)\n",
    "df = tape.gradient(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 4. 12.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-build",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70c594fb5372013e9202d7211adf83287cdf0e44ee36de7e3ad058ce8e2ca05b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
