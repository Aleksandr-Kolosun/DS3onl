{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Группа DS03-onl\n",
    "\n",
    "Студент Парфимович Алексей\n",
    "\n",
    "## Домашнее задание №16\n",
    "\n",
    "Работа с рукописными изображениями цифр:\n",
    "- Выполнить кластеризацию двумя разными методами (иерархическая кластеризация и алгоритм $K$-means), \n",
    "- Оценить качество разбиения и выбирать оптимальное число кластеров, \n",
    "- Визуализировать промежуточные результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описания набора данных\n",
    "\n",
    "Набор данных `load_digits` подмодуля `datasets` библиотеки содержит 1797 наблюдений, каждое из них представляет чёрно-белую картинку 8 $\\times$ 8 пикселей.  \n",
    "Каждая картинка – распознанная рукописная цифра от 0 до 9, \"развёрнутая\" в строку так, что NumPy-массив, в котором хранятся данные, имеет размерность 2 и величину 1797 $\\times$ 64.  \n",
    "Интенсивность цвета в каждом пикселе кодируется целым числом от 0 до 16.  \n",
    "Для каждого наблюдения задано соответствующие значения целевой переменной: какую цифру изображает каждая картинка.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Постановка задачи\n",
    "Предположим, что нам не известны истинные метки классов (цифры) и количество классов, и попробуем сгруппировать данные таким образом, чтобы качество кластеризации оказалось наилучшим, а затем посмотрим, насколько точно полученные кластеры совпадают с группами изображений одинаковых цифр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Получение данных\n",
    "В переменную `X` загрузить массив наблюдений, содержащий 1797 $\\times$ 64 числа, \n",
    "а в переменную `y` – массив истинных меток классов, содержащий 1797 чисел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "# признаки наблюдений(картинок)\n",
    "X = digits['data']\n",
    "print(f'Массив наблюдений: {X.shape}')\n",
    "\n",
    "# целевые переменные - цифры от 0 до 9\n",
    "y = digits['target']\n",
    "print(f'Массив меток классов: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализировать первые 10 картинок, расположив их в сетке 3 $\\times$ 4    \n",
    "Фон картинок должен быть белым, а изображения цифр – тёмными\n",
    "\n",
    "*Указания:*\n",
    "- Инвертировать цвета фона и изображения цифр\n",
    "- Расположить картинки на графике функцией `plt.subplot`\n",
    "- Сформировать картики из строк массива `X` методом `reshape` как матрица 8 $\\times$ 8\n",
    "- Отключить деления на координатных осях параметрами `xticks` и `yticks` функции `plt.subplot`\n",
    "- Отключить сглаживание параметром `interpolation` функции `plt.imshow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполнить инверсию цвета пикселей картинки\n",
    "X = 0 -X + 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcUAAAHmCAYAAAAC+ZUcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdaElEQVR4nO3dfZDVZdkH8GsBCbJ9wdJq3RXESooUCtNBbaRJbRh04B8sswR70xEnVqZGbEahFwv/0bWXQW0ccCo1tQQnpxitwGHKEZFldJqxzKDF1ewFdhdTtN3z/NENPTzpw94/93fO0fP5zDjTnu7rXPdhb853f2cP12mqVCqVAABiTK03AAD1QigCQCIUASARigCQCEUASIQiACRCEQCScUULh4eHo6+vL5qbm6OpqWk090QBlUolBgcHo729PcaMabyfdZzH+uI8Oo/1ZqRnsnAo9vX1RWdnZ9FyStLb2xsdHR213kbVOY/1yXmk3hzqTBYOxebm5gMNWlpait7NId1zzz3ZNStXrsxaP2fOnNJ7RERMmjQpu2akBgYGorOz88D3pdFU6zwWMW/evKz1/f392T2uvPLK7JrcfeVwHuv3PG7evDlr/Sc/+cnsHieccEJ2zX333Zddk2OkZ7JwKO5/SaClpaXUb/qb3/zm7Jrcl2vGjx+f3aPIY67GX45GfammWuexiHHj8v6ajR07NrtHkb8nzmN56vk8Hn744Vnri3wPc898RHXOY8ShH0/jvdgPAK9CKAJAIhQBIBGKAJAIRQBIhCIAJEIRABKhCACJUASARCgCQFJ4zFu1LF++PLvmqaeeylq/e/fu7B5HHHFEds2dd96ZtX7hwoXZPag/ra2tWes3btyY3aNIzfz587NrqC/bt2/Prsmd9dzW1pbdY8eOHdk19cKVIgAkQhEAEqEIAIlQBIBEKAJAIhQBIBGKAJAIRQBIhCIAJEIRABKhCABJ1Wefbt26NWt97hzTiIg//vGPWeunTp2a3eOss87Krsl97Gaf1p8isyY3bdpUwk4ONnPmzNJ7UH/WrVuXXZN7VhYsWJDdY+XKldk19cKVIgAkQhEAEqEIAIlQBIBEKAJAIhQBIBGKAJAIRQBIhCIAJEIRABKhCACJUASApOoDwXfv3p21ftasWdk9igz4zlVkX9SfG264IWt9kUHHe/bsya7JNWfOnNJ7UH+6urqya6ZMmVJ6j/nz52fX1AtXigCQCEUASIQiACRCEQASoQgAiVAEgEQoAkAiFAEgEYoAkAhFAEiEIgAkdT/79MwzzyxpJ69N7uOIiJg0aVIJO+G1WLp0adb6xYsXZ/doa2vLrslVZL7q5MmTR38jvCb9/f1Z67u7u7N7rFu3Lrsm16233lp6j7K4UgSARCgCQCIUASARigCQCEUASIQiACRCEQASoQgAiVAEgEQoAkAiFAEgEYoAkFR9IHjuUOytW7eWtJP/KDLcu8i+Fi5cmF0DI9HT05NdM2PGjNHfCK/JypUrs9YXGQieq8gA8dbW1tHfSJW4UgSARCgCQCIUASARigCQCEUASIQiACRCEQASoQgAiVAEgEQoAkAiFAEgEYoAkFR9IPjUqVOz1hcZvH3XXXeVur6oK664oip9gNenxYsXZ63fuHFjdo/c4fELFizI7jF//vzsmosuuqj0HiPhShEAEqEIAIlQBIBEKAJAIhQBIBGKAJAIRQBIhCIAJKWH4ve+972YMmVKTJgwIU455ZTYvn172S3hFT344INx7rnnRnt7ezQ1NcW6detqvSUa1Le+9a340Ic+FM3NzXHUUUfFggUL4oknnqj1toiSQ/HHP/5xLFu2LFasWBGPPvpozJgxIxYvXhx/+9vfymwLr+j555+PGTNmxPe+971ab4UGt2nTpliyZEk89NBDcf/998fLL78cZ599drzwwgu13lrDK3XM23XXXRef//znD4zvufHGG+Pee++Nu+++Oy655JIyW8N/mTt3bsydO7fW24D4xS9+cdDXa9eujaOOOip+97vfxaxZs2q0KyJKDMWXXnoptm7dGldeeeWB28aMGRMf+9jH4oknnhjxDNRVq1Zl916+fHnW+iKH8JFHHsmu4fWvtbU1uyZ3RuP69euzexSZgblo0aLsGsrR398fEREnn3xyvP/97x9x3bZt27J75f4Ka8WKFdk9ipzhY489Nmv962726d/+9rcYGhqKt7/97Qfd/va3vz2effbZstoCvK4MDw9HV1dXnHbaaVmBSDmq/ikZAPzHkiVL4vHHH4/NmzfXeitEiaH4tre9LcaOHRt/+ctfDrr9L3/5S7zjHe8oqy3A68Zll10WP/vZz+LBBx+Mjo6OWm+HKPHl0/Hjx8esWbPil7/85YHbhoeH45e//GXMnj27rLYAda9SqcRll10W99xzT/zqV7/K/n0a5Sn15dNly5bFokWL4qSTToqTTz45uru74/nnn8/+MEkYDXv37o0nn3zywNd/+tOfoqenJ4444og45phjargzGs2SJUvitttui/Xr10dzc/OB91m0trbGxIkTa7y7xlZqKH784x+Pv/71r3H11VfHs88+GzNnzoxf/OIX//XmG6iGRx55JD7ykY8c+HrZsmUR8e93Ya5du7ZGu6IRrV69OiIi5syZc9Dta9asicWLF1d/QxxQ+httLrvssrjsssvKbgOHNGfOnKhUKrXeBjiHdczsUwBIhCIAJEIRABKhCABJ4Tfa7P9F8cDAwKht5pUUmRo/PDyctf7ll1/O7lH24861fz+N+gv8ap3HIoqcr1wvvfRSdk2Zf1bOY/2ex71792atr8b5jYjYt29f1vrcP9uRnsmmSsFTu2vXrujs7CxSSol6e3sbcjKG81ifnEfqzaHOZOFQHB4ejr6+vmhubo6mpqbCG2R0VCqVGBwcjPb29hgzpvFeFXce64vz6DzWm5GeycKhCABvNI33IxwAvAqhCACJUASARCgCQCIUASARigCQCEUASIQiACRCEQASoQgAiVAEgEQoAkAiFAEgEYoAkAhFAEiEIgAk44oW+mTp+uKTzp3HeuI8Oo/1ZqRnsnAo9vX1RWdnZ9FyStLb2xsdHR213kbVOY/1yXmk3hzqTBYOxebm5gMNWlpait7NIV1//fXZNStXrsxaP2XKlOweGzduzK6ZNGlSds1IDQwMRGdn54HvS6Op1nksor+/P2v9JZdckt3j9ttvz64pk/NYnfM4b9687Jpjjjkma/3q1auze9SjkZ7JwqG4/yWBlpaWUr/pEyZMKO2+9yvy8k6Rx1yNJ+tGfammWuexiEqlkrX+sMMOy+5Rb495P+ex3PM4blz+U/j48eOz1tfr2SrqUGey8V7sB4BXIRQBIBGKAJAIRQBIhCIAJEIRABKhCACJUASARCgCQFJ4ok1Ry5cvz1p/1113Zfe46aabstZffPHF2T22bt2aXXPmmWdm1/D6t3bt2qz1H/jAB8rZCG84O3bsyK7JHVGZe34jio3O/NOf/pRdUwZXigCQCEUASIQiACRCEQASoQgAiVAEgEQoAkAiFAEgEYoAkAhFAEiEIgAkVZ99+oUvfCFr/RVXXJHd46STTspaP3Xq1Owe5pg2pv7+/uya3NmRXV1d2T127tyZXZNr8uTJpfcgT1tbW132mDNnTnZN7t+t1tbW7B4j4UoRABKhCACJUASARCgCQCIUASARigCQCEUASIQiACRCEQASoQgAiVAEgEQoAkBS9YHgucO3n3rqqeweuTVFhnvv3r07u2bSpEnZNdSX3OHeERE7duzIWr9o0aLsHpdffnl2Te6g5xUrVmT3oFxFhrT39PRkrd+zZ092j5kzZ2bXlDXgO5crRQBIhCIAJEIRABKhCACJUASARCgCQCIUASARigCQCEUASIQiACRCEQCSqs8+zZU7KzUi4h//+EfW+rPOOiu7R5Ga+++/P2u9WanlW79+fdb6rq6u7B6LFy/OrsnV3d2dXVNkjiv1Zd26ddk1mzZtylqfOys1otjfk1xLly4t5X5dKQJAIhQBIBGKAJAIRQBIhCIAJEIRABKhCACJUASARCgCQCIUASARigCQCEUASOp+IHgRuYO0cwd1R0RcfPHF2TXXXntt1vpVq1Zl9yBPW1tbqesj8gdvFxnAXMSCBQuq0of6csYZZ9R6C69ox44dtd5CRLhSBIADhCIAJEIRABKhCACJUASARCgCQCIUASARigCQCEUASIQiACRCEQASoQgASd0PBF++fHl2zZlnnpm1fvfu3dk9HnjggeyahQsXZtdQrtzhyEXOyvbt27PWz5kzJ7vH4sWLs2taW1uza6gv69evz67JHWq/cuXK7B5F1MuAeleKAJAIRQBIhCIAJEIRABKhCACJUASARCgCQCIUASARigCQlBaKq1evjhNPPDFaWlqipaUlZs+eHT//+c/LagdZVq1aFU1NTdHV1VXrrdCAVq5cGU1NTQf9N23atFpviyhxzFtHR0esWrUq3v3ud0elUolbb7015s+fH9u2bYvp06eX1RYOacuWLXHTTTfFiSeeWOut0MCmT59+0LjIcePqfupmQyjtu3Duuece9PU111wTq1evjoceeigrFCdNmpTd++KLL86uyVVkjulNN91Uwk7IsXfv3rjgggvi+9//fnzjG9+oSs/cWZN79uzJ7lFk9im1NW7cuHjHO97xmu5j48aN2TXd3d2vqedIFDmPuXOIy1KV3ykODQ3FHXfcEc8//3zMnj27Gi3hFS1ZsiTmzZuXPTQeRtsf/vCHaG9vj6lTp8YFF1wQf/7zn2u9JaLkT8l47LHHYvbs2fHiiy/GW97ylrjnnnvife97X5kt4VXdcccd8eijj8aWLVtqvRUa3CmnnBJr166N448/Pp555pn46le/Gh/+8Ifj8ccfj+bm5lpvr6GVGorHH3989PT0RH9/f9x9992xaNGi2LRpk2Ck6np7e2Pp0qVx//33x4QJE2q9HRrc3LlzD/zvE088MU455ZSYPHly3HnnnfHZz362hjuj1FAcP358vOtd74qIiFmzZsWWLVvihhtu8Ls1qm7r1q3x3HPPxQc/+MEDtw0NDcWDDz4Y3/3ud2Pfvn0xduzYGu6QRtbW1hbvec974sknn6z1VhpeVd/uNDw8HPv27atmS4iIiI9+9KPx2GOPHXTbRRddFNOmTYsrrrhCIFJTe/fujT/+8Y/x6U9/utZbaXilheKVV14Zc+fOjWOOOSYGBwfjtttui40bN8aGDRvKagmvqrm5Od7//vcfdNvhhx8eb33rW//rdijbl770pTj33HNj8uTJ0dfXFytWrIixY8fG+eefX+utNbzSQvG5556LCy+8MJ555plobW2NE088MTZs2BBnnXVWWS0BXhd27doV559/fvz973+PI488Mk4//fR46KGH4sgjj6z11hpeaaF4yy23lHXXMCqK/BsvGA133HFHrbfAqzD7FAASoQgAiVAEgKTw7xQrlUpERAwMDIzaZl7Jiy++mF0zPDxcwk4O9tJLL2XXlPlntf++939fGk21zmMRg4ODpfd4/vnns2ucx/JU6zzW6z9xq7fnx/99/4c6k02Vgqd2165d0dnZWaSUEvX29kZHR0ett1F1zmN9ch6pN4c6k4VDcXh4OPr6+qK5uTmampoKb5DRUalUYnBwMNrb22PMmMZ7Vdx5rC/Oo/NYb0Z6JguHIgC80TTej3AA8CqEIgAkQhEAEqEIAIlQBIBEKAJAIhQBIBGKAJAIRQBIhCIAJEIRABKhCACJUASARCgCQCIUASARigCQjCta6JOl64tPOnce64nz6DzWm5GeycKh2NfXF52dnUXLKUlvb290dHTUehtV5zzWJ+eRenOoM1k4FJubmw80aGlpKXo3pZg3b17W+v7+/uwemzdvzq4p08DAQHR2dh74vjSaap3H1atXZ9fs2bMna/19992X3eOxxx7LrmltbS2tx+DgYEyfPt15LPk8Ll++PLsm93x98pOfzO5x6aWXZtfknsdcI32OLByK+18SaGlpqbtQHDcu72GNHTs2u0e9Peb9GvWlmmqdxwkTJpReU+Q8FpF7Vor8uTqP5Z7HN73pTdk1uS9nFznzRR5ztZ5TD3UmG+/FfgB4FUIRABKhCACJUASARCgCQCIUASARigCQCEUASIQiACRCEQCSwmPeqmX9+vXZNRs3bsxav3LlyuweMFJtbW1Z67u7u7N7XH/99dk1uTN/c2ZTNup4t2rr6ekpvcfatWuza3KfgyMifv3rX2fXlMGVIgAkQhEAEqEIAIlQBIBEKAJAIhQBIBGKAJAIRQBIhCIAJEIRABKhCABJ3c8+rcZc0gULFpTegzeGpUuXlt7jq1/9anbNzp07s2uKzKekvsycOTO7ZsqUKVnr16xZk91j0qRJ2TWbNm3KWn/GGWdk9xgJV4oAkAhFAEiEIgAkQhEAEqEIAIlQBIBEKAJAIhQBIBGKAJAIRQBIhCIAJEIRAJK6Hwi+Z8+e7JrcIbkzZszI7sEbQ+4Q4moM0e7u7i69R0TEunXrstYvWrSonI1Q2OLFi7Nrcp8fd+zYkd2jra0tuyZ3UHlZXCkCQCIUASARigCQCEUASIQiACRCEQASoQgAiVAEgEQoAkAiFAEgEYoAkLwhZ5/mztC74YYbsnssWLAgu2by5MnZNZQr96xs27Ytu0fufNUicueYRkScccYZo78RqqrI82OuIvN+i8xLrZfnR1eKAJAIRQBIhCIAJEIRABKhCACJUASARCgCQCIUASARigCQCEUASIQiACRCEQCSuh8InjuwOSJ/gG2RobpdXV3ZNT09PVnrZ8yYkd2DPLlDiIsM3m5qaiq9h+Hebwzbt2/PWj9nzpzsHitXrsxaX2S4d5EPTMg992UNEHelCACJUASARCgCQCIUASARigCQCEUASIQiACRCEQASoQgAiVAEgEQoAkAiFAEgqfuB4IsXL86uyR3WXWSwbJEhubkDbw0Erz+XX355dk1bW1vW+iJDnnljyP0AhNyzFZH//FjkuW7mzJnZNWvXrs1av2LFiuweI+FKEQASoQgAiVAEgEQoAkAiFAEgEYoAkAhFAEiEIgAkpYbi008/HZ/61KfirW99a0ycODFOOOGEeOSRR8psCa9oypQp0dTU9F//LVmypNZbowENDQ3FVVddFccee2xMnDgxjjvuuPj6178elUql1ltreKVNtNm9e3ecdtpp8ZGPfCR+/vOfx5FHHhl/+MMfYtKkSWW1hFe1ZcuWGBoaOvD1448/HmeddVYsXLiwhruiUV177bWxevXquPXWW2P69OnxyCOPxEUXXRTjx4+PSy65pNbba2ilheK1114bnZ2dsWbNmgO3HXvssWW1g//XkUceedDXq1atiuOOOy7OOOOMGu2IRvab3/wm5s+fH/PmzYuIf7+Scfvtt8ejjz5a451RWijee++98bGPfSwWLlwYmzZtiqOPPjouvfTS+PznP591P0Vmn+bO6suduRcRhZ5MFyxYkF3D6HvppZfihz/8YSxbtiyampqyajdu3JjdL/d8tba2Zvfg9eXUU0+Nm2++OX7/+9/He97znti+fXts3rw5rrvuuqzvf5Hnodx5qUXmq86fPz+7Jncma1lKC8WnnnoqVq9eHcuWLYuvfOUrsWXLlvjiF78Y48ePj0WLFpXVFg5p3bp1sWfPnkI/cMFoWL58eQwMDMS0adNi7NixMTQ0FNdcc01ccMEFtd5awystFIeHh+Okk06Kb37zmxER8YEPfCAef/zxuPHGG4UiNXXLLbfE3Llzo729vdZboUHdeeed8aMf/Shuu+22mD59evT09ERXV1e0t7d7fqyx0kLxne98Z7zvfe876Lb3vve98ZOf/KSslnBIO3fujAceeCB++tOf1norNLAvf/nLsXz58vjEJz4REREnnHBC7Ny5M771rW8JxRor7Z9knHbaafHEE08cdNvvf//7Qp9dCKNlzZo1cdRRRx14gwPUwj//+c8YM+bgp9+xY8fG8PBwjXbEfqVdKV5++eVx6qmnxje/+c0477zz4uGHH46bb745br755rJawv9reHg41qxZE4sWLYpx4+r+87V5Azv33HPjmmuuiWOOOSamT58e27Zti+uuuy4+85nP1HprDa+0Z4YPfehDcc8998SVV14ZX/va1+LYY4+N7u5uv0imZh544IH485//7ImHmvvOd74TV111VVx66aXx3HPPRXt7e1x88cVx9dVX13prDa/UH5fPOeecOOecc8psASN29tlnmxhCXWhubo7u7u7o7u6u9Vb4P8w+BYBEKAJAIhQBIBGKAJAUfqPN/jcsDAwMjNpmXkmR+9+3b1/W+iJvvnj55Zeza/bu3Zu1Puex71/bqG8kqdZ5/N+ftDFS//znP7PWl/0YqsF5rM55LPI8lKtaz4+5f1a5c4tHeiabKgVP7a5du6Kzs7NIKSXq7e2Njo6OWm+j6pzH+uQ8Um8OdSYLh+Lw8HD09fVFc3NzdmIz+iqVSgwODkZ7e/t/TcpoBM5jfXEencd6M9IzWTgUAeCNpvF+hAOAVyEUASARigCQCEUASIQiACRCEQASoQgAiVAEgEQoAkAiFAEgEYoAkAhFAEiEIgAkQhEAEqEIAIlQBIBkXNFCnyxdXxr9k84BRkPhUOzr64vOzs7R3AujoLe3Nzo6Omq9DYDXpcKh2NzcHBH/fhJuaWkZtQ39X+eff352zcDAQNb6++67L7tHvRkYGIjOzs4D3xcA8hUOxf0vmba0tJQaiocddlh2zbhxeQ+rzP1Xm5eyAYrzyycASIQiACRCEQASoQgAiVAEgEQoAkAiFAEgEYoAkAhFAEgKT7QpaufOnVnr169fX9JO/qPIFJiZM2dm12zbti27BoDqcaUIAIlQBIBEKAJAIhQBIBGKAJAIRQBIhCIAJEIRABKhCACJUASARCgCQFL12ad79uwpvcecOXOy1k+ZMiW7x8aNG7NrAKhvrhQBIBGKAJAIRQBIhCIAJEIRABKhCACJUASARCgCQCIUASARigCQCEUASIQiACRVHwheZPh2rnXr1mWtX7BgQXaPagw2B6C6XCkCQCIUASARigCQCEUASIQiACRCEQASoQgAiVAEgEQoAkAiFAEgEYoAkFR99mlra2vW+pkzZ2b3aGtry1rf1dWV3aOnpye7ZufOnVnrJ0+enN0DgOJcKQJAIhQBIBGKAJAIRQBIhCIAJEIRABKhCACJUASARCgCQCIUASARigCQCEUASKo+EDzXtm3bsmu2b9+etX7GjBnZPYpYunRp1vp169aVsxEAXpErRQBIhCIAJEIRABKhCACJUASARCgCQCIUASARigCQCEUASIQiACRCEQASoQgASd0PBC8id8D35Zdfnt1j7dq12TUGfAPUN1eKAJAIRQBIhCIAJEIRABKhCACJUASARCgCQCIUASARigCQlBqKg4OD0dXVFZMnT46JEyfGqaeeGlu2bCmzJQAUVmoofu5zn4v7778/fvCDH8Rjjz0WZ599dpx55pnx9NNPl9kWAAppqlQqlSKFAwMD0draGv39/dHS0vJf//8LL7wQzc3NsX79+pg3b96B22fNmhVz586Nb3zjGyPqU2QuaU9PT9b6PXv2ZPcoMvs0dyZrjkN9PwA4tNKuFP/1r3/F0NBQTJgw4aDbJ06cGJs3by6rLQAUVlooNjc3x+zZs+PrX/969PX1xdDQUPzwhz+M3/72t/HMM8+U1RYACiv1d4o/+MEPolKpxNFHHx1vetOb4tvf/nacf/75MWaMN70CUH9KTafjjjsuNm3aFHv37o3e3t54+OGH4+WXX46pU6eW2RYACqnKJdvhhx8e73znO2P37t2xYcOGmD9/fjXaAkCWcWXe+YYNG6JSqcTxxx8fTz75ZHz5y1+OadOmxUUXXVRmWwAopNQrxf7+/liyZElMmzYtLrzwwjj99NNjw4YNcdhhh5XZFgAKKfVK8bzzzovzzjuvzBYAMGq8DRQAEqEIAIlQBICk8O8U949MHRgYGLXNvJJ9+/Zl1/zrX//KWj80NJTdY+/evdk1Zf5Z7b/vgqNsAYjXMBB8165d0dnZOdr74TXq7e2Njo6OWm8D4HWpcCgODw9HX19fNDc3R1NT02jvi0yVSiUGBwejvb3dGD2AggqHIgC80bikAIBEKAJAIhQBIBGKAJAIRQBIhCIAJEIRABKhCACJUASARCgCQCIUASARigCQ/A+ridQwLEamKwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создать объект для рисования графиков\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Добавить объекты графиков,\n",
    "# отобразить в них первые 10 строк массива X,\n",
    "# как матрицу 8х8 пикселей в сетке 3х4 \n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(4, 3, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.reshape(X[i],[8,8]), interpolation='none')\n",
    "    # Отобразить целевую метку класса для каждой картинки\n",
    "    ax.text(0, 7, str(y[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Кластеризация и оценка качества\n",
    "\n",
    "Используя алгоритмы иерархической кластеризации и $K$ средних, получить разбиение массива `X` на 10 кластеров.\n",
    "\n",
    "*Указания:*\n",
    "- Оба раза должен получиться массив из 1797 чисел – номеров кластеров.\n",
    "- `KMeans` делает несколько (по умолчанию 10) запусков со случайными центрами и из полученных разбиений выводит лучшее в терминах среднего внутрикластерного расстояния. Чтобы улучшить качество предсказаний, можно увеличить число запусков, например, до 100. Это параметр `n_init` в конструкторе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте центры кластеров, полученных каждым из двух способов. Это опять должны быть картинки на сетке 3 $\\times$ 4 с белым фоном и тёмными контурами. Прокомментируйте: какой из двух алгоритмов даёт центры кластеров, больше похожие на типичные начертания цифр?\n",
    "\n",
    "*Указания:*\n",
    "- Центр кластера – это среднее по всем наблюдениям, входящим в кластер, т. е. по какому-то набору строк из `X`.\n",
    "- Чтобы выбрать наблюдения, входящие в кластер номер `i`, используйте индексацию по булевозначной маске. Саму маску можно получить из массива предсказанных номеров кластеров и числа `i` оператором `==`.\n",
    "- Усреднять NumPy-массив вдоль какой-нибудь из осей умеет функция `np.mean`. Ознакомьтесь со справкой к ней. Нам нужно усреднение по строкам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ситуации, когда истинное число кластеров неизвестно, подбирают оптимальное число кластеров. При этом учитывают две величины: внутрикластерное расстояние (чем меньше, тем лучше) и межкластерное расстояние (чем больше, тем лучше). Так как две эти величины не достигают оптимума одновременно, обычно оптимизируют какой-нибудь функционал от них. Один популярный функционал называется \"силуэт\" (silhouette). Вот как он вычисляется.\n",
    "\n",
    "Пусть $X$ – множество наблюдений, $M \\subset X$ – один из кластеров, на которые оно разбито в результате кластеризации, $\\rho$ – метрика на $X$. Выберем какое-нибудь одно наблюдение $x \\in M$. Обозначим $a(x)$ среднее расстояние от $x$ до точек $x'$ из того же кластера:\n",
    "$$\n",
    "a(x) = \\frac{1}{|M|} \\sum_{x' \\in M} \\rho(x,\\, x')\n",
    "$$\n",
    "\n",
    "Обозначим $b(x)$ минимум средних расстояний от $x$ до точек $x''$ из какого-нибудь другого кластера $N$:\n",
    "$$\n",
    "b(x) = \\min_{N \\ne M} \\frac{1}{|N|} \\sum_{x'' \\in N} \\rho(x,\\, x'')\n",
    "$$\n",
    "\n",
    "Силуэт – это разность межкластерного и внутрикластерного расстояний, нормированная до отрезка $[-1,\\, 1]$ и усреднённая по всем наблюдениям:\n",
    "$$\n",
    "\\frac{1}{|X|} \\sum_{x \\in X} \\frac{b(x) - a(x)}{\\max(a(x),\\, b(x))}\n",
    "$$\n",
    "\n",
    "В scikit-learn силуэт считается функцией `silhouette_score` из подмодуля `metrics`. На вход нужно передать массив наблюдений и результат кластеризации.\n",
    "\n",
    "\n",
    "Для числа $K$ от 2 до 20 включительно получите разбиение массива `X` на $K$ кластеров каждым из двух методов. Посчитайте силуэт. Посчитанные значения силуэта сохраните в переменную и визуализируйте в виде графика в координатах: число $K$ – значение силуэта. При каком числе кластеров достигается максимум силуэта?\n",
    "\n",
    "*Указания:*\n",
    "- Не забудьте, что функция `range` не захватывает правый конец диапазона.\n",
    "- Под значения силуэта можно завести два списка: один для иерархической кластеризации, другой для $K$ средних.\n",
    "- Рисовать графики умеет функция `plt.plot`. Ознакомьтесь со справкой к ней.\n",
    "- На одной картинке можно разместить несколько графиков, это просто несколько последовательных вызовов `plt.plot`.\n",
    "- Чтобы добавить легенду (подписи к графикам), можно воспользоваться функцией `plt.legend`. Местоположение легенды контролируется параметром `loc`.\n",
    "- Чтобы подписать координатные оси, можно воспользоваться функциями `plt.xlabel` и `plt.ylabel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда известно \"правильное\" (в каком-нибудь смысле) разбиение на кластеры, результат кластеризации можно сравнить с ним, используя такие меры, как однородность (homogeneity), полнота (completeness) и их среднее гармоническое – $V$-мера. Определения этих величин довольно громоздкие и основаны на понятии [энтропии распределения вероятностей](https://ru.wikipedia.org/wiki/Информационная_энтропия); подробности излагаются в [этой статье](http://aclweb.org/anthology/D/D07/D07-1043.pdf). На практике достаточно знать, что однородность, полнота и $V$-мера заключены между нулём и единицей – чем больше, тем лучше.\n",
    "\n",
    "Так как мы знаем, какую цифру на самом деле изображает каждая картинка (это массив `y`), мы можем использовать однородность, полноту и $V$-меру для оценки качества кластеризации. Функции для вычисления этих величин доступны в scikit-learn, в подмодуле `metrics`, под названиями `homogeneity_score`, `completeness_score`, `v_measure_score`. Как вариант, можно использовать функцию `homogeneity_completeness_v_measure`, которая возвращает сразу тройку чисел.\n",
    "\n",
    "Повторите предыдущее задание, используя $V$-меру вместо силуэта. При каком числе кластеров достигается максимум $V$-меры?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Снижение размерности признакового пространства\n",
    "\n",
    "Иногда, особенно когда признаков много и не все они одинаково информативные, бывает полезно снизить размерность признакового пространства, то есть вместо $d$ исходных признаков перейти к рассмотрению $d' \\ll d$ новых признаков. Данные были представлены матрицей $n$ наблюдений $\\times$ $d$ исходных признаков, а теперь будут представлены матрицей $n$ наблюдений $\\times$ $d'$ новых признаков.\n",
    "\n",
    "Есть два популярных подхода к снижению размерности:\n",
    "- отобрать (select) новые признаки из числа имеющихся;\n",
    "- извлечь (extract) новые признаки, преобразуя старые, например, сделать $d'$ различных линейных комбинаций столбцов исходной матрицы $n \\times d$.\n",
    "\n",
    "Одним из широко используемых методов извлечения признаков является сингулярное разложение матрицы (singular value decomposition, SVD). Этот метод позволяет сконструировать любое число $d' \\le d$ новых признаков таким образом, что они будут, в определённом смысле, максимально информативными. Математические детали сейчас не важны; познакомиться с ними можно, например, [здесь](https://www.coursera.org/learn/mathematics-and-python/lecture/L9bCV/razlozhieniia-matrits-v-proizviedieniie-singhuliarnoie-razlozhieniie)\n",
    "(по-русски) или [здесь](https://www.youtube.com/watch?v=P5mlg91as1c) (по-английски).\n",
    "\n",
    "В scikit-learn есть несколько реализаций сингулярного разложения. Мы будем использовать класс `TruncatedSVD` из подмодуля `decomposition`. В конструктор этого класса достаточно передать один параметр `n_components` – желаемое число новых признаков. Метод `fit_transform` принимает матрицу и возвращает новую матрицу с таким же количеством строк, как прежде, и количеством столбцов, равным числу новых признаков.\n",
    "\n",
    "*<u>Замечание:</u>* Сингулярное разложение матрицы $M$ обычно пишут в виде $M = U \\Sigma V^{*}$, где $U$, $\\Sigma$ и $V$ – некие матрицы с хорошими свойствами. То, что возвращает алгоритм `TruncatedSVD`, – это сколько-то (сколько мы хотим получить) первых столбцов матрицы $U$.\n",
    "\n",
    "Выполните сингулярное разложение матрицы `X`, оставляя 2, 5, 10, 20 признаков. В каждом случае выполните иерархическую и $K$-means кластеризацию преобразованных данных (число кластеров примите равным 10). Посчитайте значения силуэта и $V$-меры. Удалось ли при каком-нибудь $d'$ получить силуэт и / или $V$-меру лучше, чем на исходных данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другая популярная техника снижения размерности, которая особенно хорошо подходит для работы с картинками, – это алгоритм t-distributed stochastic neighbor embeddings, сокращённо tSNE. В отличие от сингулярного разложения, это преобразование нелинейное. Его основная идея – отобразить точки из пространства размерности $d$ в пространство размерности 2 или 3 (обычно 2, то есть на плоскость) таким образом, чтобы как можно точнее сохранить расстояния. Математические детали есть, например, [здесь](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding), но они нетривиальны.\n",
    "\n",
    "В библиотеке scikit-learn реализацией tSNE является класс `TSNE` в подмодуле `manifold`. В конструктор можно передать параметр `n_components`, а можно и не передавать: по умолчанию он равен 2. Метод `fit_transform` работает аналогично тому, как и у `TruncatedSVD`.\n",
    "\n",
    "\n",
    "Выполните tSNE-преобразование матрицы `X`, оставив 2 признака. Визуализируйте данные, преобразованные таким образом, в виде точечной диаграммы: первый признак вдоль горизонтальной оси, второй признак вдоль вертикальной оси. Подсветите разными цветами группы точек, соответствующих разным цифрам.\n",
    "\n",
    "*Указания:*\n",
    "- Точечную диаграмму умеет рисовать функция `plt.scatter`. Ознакомьтесь со справкой к ней.\n",
    "- За цвета точек отвечает параметр `c` у функции `plt.scatter`. Передать в него надо истинные метки классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для tSNE-преобразованных данных с 2 признаками выполните иерархическую и $K$-means кластеризацию (число кластеров примите равным 10). Посчитайте значения силуэта и $V$-меры. Удалось ли получить силуэт и / или $V$-меру лучше, чем на исходных данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для самого лучшего разбиения, которое вам удалось получить (на ваше усмотрение, лучшего в терминах силуэта или $V$-меры), опять визуализируйте картинками центры кластеров. Удалось ли добиться, чтобы каждый кластер соответствовал какой-нибудь одной цифре?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Итоги\n",
    "\n",
    "Напишите в свободной форме, какие выводы вы сделали из выполненной работы. Ответьте, как минимум, на следующие два вопроса:\n",
    "- Какой из двух методов даёт более осмысленные кластеры – иерархическая кластеризация или алгоритм $K$ средних? Зависит ли это от настроек каждого алгоритма? От критериев оценивания качества?\n",
    "- Удаётся ли улучшить качество кластеризации, снижая размерность признакового пространства?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте датасет [MNIST Handwritten Digits](http://yann.lecun.com/exdb/mnist). Как сделать это с помощью scikit-learn, написано [здесь](http://scikit-learn.org/stable/datasets/index.html#downloading-datasets-from-the-mldata-org-repository). MNIST Handwritten Digits – это 70 тысяч распознанных рукописных изображений цифр, каждое размером 28 $\\times$ 28 пикселей. Попробуйте прокластеризовать этот датасет и добиться как можно лучших значений силуэта и $V$-меры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
